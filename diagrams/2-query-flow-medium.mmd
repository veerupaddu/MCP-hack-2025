sequenceDiagram
    participant User
    participant Modal
    participant RAGModel
    participant Embeddings
    participant ChromaDB
    participant LLM

    User->>Modal: modal run query --question "..."
    
    Note over Modal,RAGModel: Container Startup (if cold)
    Modal->>RAGModel: Initialize
    RAGModel->>Embeddings: Load embedding model (GPU)
    RAGModel->>LLM: Load Mistral-7B (GPU)
    
    Note over Modal,LLM: Query Processing
    Modal->>RAGModel: Process question
    RAGModel->>Embeddings: Convert question to vector
    RAGModel->>ChromaDB: Search similar documents
    ChromaDB-->>RAGModel: Top 3 matching docs
    
    RAGModel->>LLM: Generate answer + context
    LLM-->>RAGModel: Answer
    
    RAGModel-->>User: Display answer + sources
